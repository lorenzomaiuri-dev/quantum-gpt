{
    "tokenizer_class": "BiCharTokenizer",
    "batch_size": 64,
    "block_size": 128,
    "max_iters": 20000,
    "eval_interval": 100,
    "learning_rate": 0.0003,
    "device": "cuda",
    "eval_iters": 200,
    "n_embd": 128,
    "n_head": 64,
    "n_layer": 8,
    "dropout": 0.15,
    "use_quantum": false,
    "n_qlayers": 2,
    "q_device": "default.qubit",
    "n_qubits": 2
}